timer.py
------------------------------------------

Description: 
    The python file responsible to run every 5 minutes to detect laptop activity. It also saves the overall browser activity in a browser_history_log.json file.

Sequence of progess and development:

Whenever the cronjob calls the timer.py function(every 5 minutes) we need the name of the current running process e.g. terminal, nautilus, vscode, etc or in case of browser, we need the URL of the active tab opened in that browser. 

Hence, we first need to identify which process is running without using any external dependency. There are many stackoverflow solutions to find the active process id(pid) currently running, but there were many complicacies in them. One of them was the concept of parent and child pids which made it complex to decode the actual pid of the current process. 

With more and more searching, another UNIX command was explored namely xdotool. As per the man page of xdotool, it is programatical way to simulate keyboard input and mouse activity, move and resize windows , etc. This tool brought new possibilities of activity detection with common methodology for offline and browser activity detection. 

Using getactivewindow and getwindowpid attributes of xdotool, we get the exact pid of current active process in the system monitor. Now using the ps command, we fetch the active process name e.g. gnome-terminal, totem, etc. But here, we are only able to get the browser name if a broswer is active right now. So how to get the current active website opened in the browser. 

As we know that ctrl + L command shifts the focus to the browser URL area, we can thence copy it using ctrl + C command and fetch the copied URL in the program using ctrl + V. This when implemented using xdotool worked as expected. But there came many unexpected caveats with this technique. When the user is browsing or typing anything or has anything copied in the system clipboard for any future work, our implementation interrupts the work by changing focus to the URL area, and due to the internal ctrl + C command, the clipboard is also now different than expected by the user. Hence, causing too much trouble to the user. 

We, therefore needed to create 2 other processes to deal with just the broswer data extraction part. 1 was a function named browser_activity(), while other was a python program named processreader.py having the method fetch_links_firefox(). 

processreader.fetch_links_firefox():
""" Returns a dictionary of all tabs currently opened in firefox along with their URLS.
E.g. {'Facebook â€“ log in or sign up': 'https://www.facebook.com/'}} """

    Using regular expression, finds the correct path to the default mozilla history file(the file which has URL to all websites opened in firefox).

    After decompressing the database file, we get the list of all opened websites along with their URLs as a dictionary. 

timer.browser_activity():
""" Returns the website name which is active in the firefox browser. Sample output : "facebook" """

    Finds the current title of the active tab in the broswer using xdotool. 
    
    Now calls the fetch_links_firefox() function to get all the list of webistes and URLs opened right now. Searches for the current title in that dictionary and returns the domain name from the link. E.g. if link is support.mozilla.com, or mozilla.com it returns "mozilla".
    
The returned domain name is stored in a variable named tab. Now from the entry in timer.json(the file with activity data for each day) we goto the "browser" sub-dictionary and increase the usage time of <tab> by 5 minutes(since we check for activity every 5 minutes itself).

If the active window was not a browser, then we simply create an entry for that process in current date's entry and increase count by 5.

The final updated database is dumped. 
END of process.

Other side features in timer.py:

    1. Whenever a new day starts, first save the activity bar chart by accessing the timer data from the previous date and display it automatically as per activity name. 

    2. A global history file namely "browser_history_log.json" is maintained where every website ever accessed is stored along with the frequency of times it is accessed since last updation. This global history file will be used for efficient categorization purpose where the top-k most used domains which are still unclassified would be prompted to the user for their correct intended category. 

    E.g. If "itsfoss.com" is a new entry but frequently used, it would be prompted to the user, who if enters to as an educational website, then "itsfoss.com" will be mapped to educational for all future references. 
    
Activation:

    For this timer.py to work, we need to set it inside cronjob for every 5 minutes but before that the necessary virtual environment must be activated. For this we use a shell script program file(venv_activate.sh) which will first activate the virtualenv and then call the timer.py program. 

    The cronjob is written as :
    */5 * * * * /home/raj/Documents/scheduler/venv_activate.sh 2>/home/raj/Documents/scheduler/timer_err.txt # timer
--------------------------------------------------------------------

history_reader.py:
----------------------------------

Description:
    """ Program to read all history from firefox in the system and use their frequency count for categorization purpose. To be used as cron job set to once every month."""

We define 4 categories in that would be the basis of our whole Scheduler:
    1. Academic
    2. Non-Academic
    3. Entertainment
    4. Miscellaneous 

The methods first detect whether its an installation-run(program run for the first time) or a normal run. 

If an installation-run, all the history in firefox till now will be used to be sorted as per their frequency of visit, and prompted to the user for classify the domain as either of the 4 categories mentioned above. This is followed by a categorisation process for all the system applications. 

Otherwise, if its a normal run, then simply access the "browser_history_log.json" file(where browser tabs opened on daily basis is stored everyday) and do the same sorting and categorisation process with the help of user. 

Methods:

1. find_all_applications():
"""  scan /usr/share/applications folder and return a dictionary of all applications in the system with mapping of system name to display name. E.g: nautilus: File Explorer. """  

2. firefox_history_scan():
""" Scan the sqlite file of firefox history in the PC and add all visited URLs along with their visit count to browser_history_log.json. This will be used to request the user for categorize the most visited yet unresolved domains in the browser."""

    Function to first find the correct path to the places.sqlite file in the PC(the path is unique for all systems, hence no fixed path is defined). The file places.sqlite is a sqlite db file to store different data related to firefox browser history. More details about the table schema can be found at: https://developer.mozilla.org/en-US/docs/Mozilla/Tech/Places/Database. 

    Since a system has usually multiple profiles within firefox browser, there exists multiple places.sqlite. The one which is into current use is locked for safety using PRAGMA lock feature in sqlite. To bypass this, whenever we need to access that locked db file, we need to first create a copy of that file, access that duplicate file and delete it after use. 
    
    By running select command to query all over the history, we update our browser_history_log.json with the count of all websites listed in the history file.  

3. do_the_categorization():
""" Using the un-classified data and previously categorised data, prompt the user for top most visited unclassified websites and then put them inside categorised data after  removing it from the unclassified data. """

4. main():
    The main function to call other functions and do the work. Also has try-catch block for keyboardInterrup (Ctrl+C).

-----------------------------------------------------------------------------------------


add_birthdays.py :
-----------------------------------

Description: A program to enter birthdate and associated name as input from a user, validate the date, check whether a similar entry pre-exists before adding a new date. All data is saved in a file named "birthday_data.json".

Methods:

    1. get_valid_date();
    """ Validate the date entered by the user. If the numbers are incorrect, then return false """

    Takes input date from the user in the form of DD-MM and applies 4 different error handlers to filter unwanted input such as date >31 or alphanumeric input or format other than DD-MM, etc. If all checks are passed, then the date and month is returned. 

    2. add_birthdaays_to_dict():
    """ To add a new birthdate entry into the file"""

    To take valid date month entry of birthday along with name of the associated person into the "birthday_data.json" file.

-----------------------------------------------------------------------------

read_birthday.py :
--------------------------------------

Description: "To get current date and check for all entries which are within 1 week from today. Give a notification of all the names as a pop-up to the user. This program will be set on cronjob of every 7 days."

Working:

* Read the "birthday_data.json" and use datetime inbuilt-module to get current data
* Iterate on all the days starting from today uptill 6th day(span of 1 week) and give notification of all names along with dates. 

------------------------------------------------------------------------------------------------------

activate_birthday.sh:
-------------------------------

This is the bash script which the cronjob will execute every 7 days. Its primary job is to first activate the virtual environment, then make the read_birthday file as executable and at last run the read_birthday file.

The cronjob will look like this: 
@weekly /home/raj/Documents/scheduler/activate_birthday.sh 2>/home/raj/Documents/scheduler/birthday_err.txt # birthday

---------------------------------------------------------------------------------


youtube_scraping.py:
---------------------------------

    *Update 17 June 2020: Youtube removes category section from its website. Hence this file will always return 0. All categorisation programs will treat youtube as a separate category with its separate time quota.* 

Whenever a youtube activity is detected, we need to find which category the video belongs to. This python program will scrape that youtube page to extract the category from its html. 

What are categories?
Youtube classifies each video into one of the 15 categories by its own algorithm. Those categories include Music, Gaming, Comedy, People and Blogs, News & Politics, etc. Youtube uses the current category of the video to recommend more videos in the side bar or in future. These categories are not always completely accurate but its our best bet to classify user activity in youtube. 

Methods:

    * find_category(link):
    """ Takes the youtube link as input and returns the category of video being played in youtube. Returns "0" when no category is found for any reason."""

    This function uses beautifulSoup and requests library to first fetch the html from the given youtube link and then search for a hard-coded class inside that html which usually has the category info. It has to be made clear, that companies often rename their html tags and classes so as to defy such scrapping bots, which makes it necessary to keep maintaining and renaming the hard-coded class name inside the program. 

    The function will return the obtained class name, but if any error occurs, it will return "0" string.

-------------------------------------------------------------------------------------


toDo.py:
---------------------------------------

Objective: Make a function to add task along with options to mark them as complete/incomplete whenever one wants.  

This program will work only when manually called by the user. No cronjob will be assigned to it.

Working:
Assuming all tasks will be stored in a file named toDo.json as a dictionary of dates. Each date will correcpond tasks having deadline at that particular date as a list of list where a tuple has task name and second position will have 0 or 1(0=incomplete, 1= complete)

Methods:
    1. read_tasks():
        Given a date, display all its todos, if exists, and also show whether its completed or not.
    
    2. add_tasks():
        First, depending upon user's choice, display current date's tasks or all pending tasks untill 30 days from now.  
        Then, until the user wants take input the task entry along with its deadline. The frontend limit to deadline is 30 days from today, although any number of days can be given.  
        The task will be put into the data as key value pair where the deadline date will act as the key. E.g : "19-07-2020":[["walk the dog,0], ["Make the mini project",0]]

        Write the file and give success message.
    
    3. mark_tasks():
        """ List all pending task, and prompt user which task to mark as complete. """

        Display all upcoming incomplete tasks corresponding to their deadline and prompt user to mark one or more of the tasks as completed. Those selected tasks will be marked as 1 from 0, which indicates completed. 

To run these programs as commands from the terminal from any directory in general, we use a technique called as linking with a technical word called "symlinks". Here, we create a link between a keyword and any program we wanna run. This keyword whenever written from a recognisable path in the terminal, will directly call the associated program. To make the link recognisable by bash, we make a new directory named "bin" in root directory, and give its path to the PATH environment variable via bashrc. This was, we create some commands to do the tasks:
1. addtask : command to add an entry after displaying today's tasks .
2. showtask : command to display all pending tasks 
3. marktask : command to mark one or more tasks as completed from all pending tasks. 

references: https://stackoverflow.com/questions/6967331/how-do-i-install-a-script-to-run-anywhere-from-the-command-line

--------------------------------------------------------------------------

check_toDo.py :
--------------------------------

This program has the primary task of counting total number of completed and incompleted tasks after a deadline is over. 

To be used in as cronjob set to @daily 

Method:
    * check_delay_and_update()
    """ Check whether all tasks for previous date is complete or not. If not, then prompt user whether to extend it or discard it. Update the date's entry with [complete, incomplete count] format. Both delayed or cancelled tasks would be counted in incomplete count anyways. """

        This program will be triggered by cronjob everyday and a pop up will be made if any task is remaining. The user can choose if s/he wants to permanently leave that incomplete task or postpone it to some forward date. 

        The task list will be converted to a list of size 2 having only # of completed and # of incomplete tasks. 
        E.g. from "18-06-2020":[["task1", 1], ["task2",0], ["task3,0]] to "18-06-2020":[1, 2] i.e. 1 complete and 2 incomplete .

        Although many sources claimed that such a pop up using cronjob is not possible, it is observed that a terminal emulator called xterm can be used for this purpose using the command :
          $  xterm -title "To Do reminder" -fa monaco -fs 11 -bg black -fg green /home/raj/Documents/scheduler/check_toDos.py



 -----------------------------------------------------------------------------------

 
task_report.py:
-------------------------------------------------

Program to iterate last 7 data of toDo completition and generate and display a bar chart representing that data.

This program will be put into cronjob @weekly i.e. the program will be triggered once every week to generate a consistency plot for past 7 data points. 

Methods:
    1. generate_graph():
    """ Function to take list of dates along with corresponding completed and incompleted tasks count and represent them in a stacked bar chart. """

        @Input: a dictionary of dates and count of tasks not/done which is to be plotted.
        @Output: To generate a bar plot out of input data, save it to a given folder, and also display it. 

        Using matplotlib, make a bar plot containing 2 subplots i.e. 1 bar for completed and 1 bar for incompleted. After plot is generated, the given directory is checked for existence, if not then the directory is made and then the plot is saved inside the folder, and then a display is given using the PIL module. 

    2. get_data():
    """ Function to get at most 7 data points from the data file and send it for plotting to the generate_graph function."""

        Starting from the yesterday's date, scan for atmost 7 data points by searching through past 30 days in the data file. If not even a single data is found, then exit, else send the data for plotting. 

